# Speech-to-Text Integration

Ce projet intÃ¨gre la reconnaissance vocale pour permettre la dictÃ©e directe dans l'interface.

## Solution implÃ©mentÃ©e : Backend Rust avec VAD

### FonctionnalitÃ©s

- âœ… **Enregistrement cÃ´tÃ© backend** : Le microphone est gÃ©rÃ© par Rust, pas le navigateur
- âœ… **DÃ©tection d'activitÃ© vocale (VAD)** : webrtc-vad dÃ©tecte automatiquement quand vous parlez
- âœ… **Segmentation automatique** : DÃ©coupe l'audio en utterances basÃ©es sur les silences
- âœ… **Transcription Whisper (prÃªte)** : Infrastructure prÃªte pour transcription IA
- âœ… **Interface intuitive** : Bouton microphone avec Ã©tats visuels (ğŸ¤ â†’ ğŸ”´ â†’ â³)

### Utilisation

1. Lancez l'application avec `pnpm tauri dev`
2. Cliquez sur le bouton microphone ğŸ¤ Ã  droite du textarea
3. Autorisez l'accÃ¨s au microphone si demandÃ© (permissions systÃ¨me)
4. Parlez normalement - le bouton devient rouge ğŸ”´
5. Cliquez Ã  nouveau pour arrÃªter - le bouton devient sablier â³
6. La transcription apparaÃ®t automatiquement dans le textarea

### Composant Svelte

Le composant `SpeechInput.svelte` est rÃ©utilisable :

```svelte
<script>
  import SpeechInput from './lib/SpeechInput.svelte';
  
  let transcript = $state("");
</script>

<SpeechInput bind:value={transcript} />
```

### Props disponibles

| Prop | Type | Description | DÃ©faut |
|------|------|-------------|--------|
| `value` | `string` (bindable) | Texte transcrit | `""` |
| `onTranscript` | `(text: string) => void` | Callback appelÃ© Ã  chaque transcription | - |
| `placeholder` | `string` | Texte placeholder | `"Click microphone to speak..."` |

### CompatibilitÃ© navigateur

L'API Web Speech fonctionne sur :
- âœ… Chrome/Edge (Chromium)
- âœ… Safari (macOS/iOS)
- âŒ Firefox (support limitÃ©)

Si le navigateur ne supporte pas l'API, un message d'avertissement s'affiche.

## Solution alternative : Whisper (Backend)

### Ã‰tat actuel

Le backend Rust contient du code pour Whisper.cpp mais nÃ©cessite :

1. **ModÃ¨le Whisper** : TÃ©lÃ©charger un modÃ¨le (ggml-base.en.bin)
2. **Correction API** : L'API whisper-rs a changÃ© depuis la version utilisÃ©e
3. **Fichiers audio** : Transcription Ã  partir de fichiers WAV

### Commandes Tauri disponibles

```typescript
// DÃ©marrer l'enregistrement avec dÃ©tection de la parole
await startRecording();

// Transcrire un fichier audio (nÃ©cessite configuration)
const result = await transcribeAudio("/path/to/audio.wav");
// { text: string, language: string | null, duration_ms: number }
```

### Configuration requise (si Whisper est utilisÃ©)

```bash
# .env
WHISPER_MODEL_PATH=models/ggml-base.en.bin
```

### TÃ©lÃ©charger un modÃ¨le Whisper

```bash
mkdir -p models
cd models

# ModÃ¨le base en anglais (~140 MB)
curl -LO https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-base.en.bin

# Autres options :
# tiny.en (~75 MB) - plus rapide, moins prÃ©cis
# small.en (~466 MB) - bon compromis
# medium.en (~1.5 GB) - trÃ¨s prÃ©cis
```

## Workflow recommandÃ©

Pour la plupart des cas d'usage, **utilisez l'API Web Speech** :
- Pas de setup requis
- Fonctionne directement dans le navigateur
- Performance excellente
- Gratuit

Utilisez Whisper seulement si vous avez besoin de :
- Transcription hors ligne
- Support de langues spÃ©cifiques
- ContrÃ´le total sur le modÃ¨le

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   SpeechInput.svelte            â”‚
â”‚   (Web Speech API)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ bind:value
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   App.svelte                    â”‚
â”‚   transcript textarea           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ invoke("orchestrate")
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Backend Rust                  â”‚
â”‚   (LLM + MCP)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## DÃ©veloppement futur

Pour activer Whisper :

1. Corriger l'API whisper-rs dans `speech_to_text.rs`
2. TÃ©lÃ©charger un modÃ¨le Whisper
3. Configurer `WHISPER_MODEL_PATH`
4. CrÃ©er une UI pour choisir entre Web Speech et Whisper

## Exemple complet

```svelte
<script lang="ts">
  import { orchestrate } from './lib/tauri';
  import SpeechInput from './lib/SpeechInput.svelte';

  let transcript = $state("");
  let result = $state(null);

  async function handleOrchestrate() {
    result = await orchestrate(transcript);
  }
</script>

<div class="container">
  <div class="input-group">
    <textarea bind:value={transcript} />
    <SpeechInput bind:value={transcript} />
  </div>
  
  <button onclick={handleOrchestrate}>
    Process
  </button>

  {#if result}
    <pre>{result.markdown}</pre>
  {/if}
</div>
```

## Troubleshooting

### "Microphone access denied"
- VÃ©rifiez les permissions du navigateur
- Sur macOS : PrÃ©fÃ©rences SystÃ¨me â†’ SÃ©curitÃ© â†’ Microphone

### "Speech recognition not supported"
- Utilisez Chrome ou Safari
- Assurez-vous d'avoir une connexion internet (Web Speech nÃ©cessite une connexion)

### Le texte ne s'affiche pas
- Parlez clairement et Ã  un volume normal
- VÃ©rifiez que le microphone fonctionne dans d'autres applications
- Essayez de redÃ©marrer le navigateur
